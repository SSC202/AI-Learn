# AI_Learn 3_数学基础

## 1. 张量（Tensor）

### 张量的创建

```python
import torch

"""
	一维张量创建函数
	参数：一维张量的元素个数
"""
torch.arange()
```

- 张量的属性

`shape`：张量（沿每个轴长度）的形状；一维张量的大小和形状属性相等。

`numel`：张量的元素总数（大小）。

如果想改变张量的形状，则应使用`torch.reshape()`方法。

```python
"""
	张量变形函数
	参数：行数和列数
	注意，如果想单一指定行数（或列数），则应使得列数（行数）为-1（自动计算）
"""
torch.reshape()
```

- 零张量，单位张量和随机张量

```python
"""
	零张量创建函数
	参数：张量的形状元组
"""
torch.zeros()

"""
	单位张量创建函数
	参数：张量的形状元组
"""
torch.ones()

"""
	随机张量创建函数，随机指从均值为0，标准差为1的高斯分布中随机选取
	参数：张量的形状元组
"""
torch.randn()
```

- 张量的指定元素创建

```python
"""
	张量创建函数
	参数：具体的张量
"""
torch.tensor()

torch.tenser([[1,2,3,4],[2,3,4,5],[6,7,8,9]])
```

### 张量的按元素运算

```python
## 按元素运算符，注意，两个张量的形状要求一致

x + y  # 按元素加
x - y  # 按元素减
x * y  # 按元素乘
x / y  # 按元素除
x ** y # 按元素求幂

## 按元素逻辑运算，生成一个bool值张量
x == y 
```

### 张量的联结

```python
"""
	张量联结函数
	第一个参数：要联结的张量元组
	第二个参数 dim：联结方向 取0为列方向联结（列数一致），取1为行方向联结（行数一致）
"""
torch.cat()

torch.cat((X, Y), dim=1)
```

### 张量的索引和切片

张量中的元素可以通过索引访问。第一个元素的索引是0，最后一个元素索引是-1； 

可以指定范围以包含第一个元素和最后一个之前的元素。

## 2. 数据的预处理

### 数据集的读取

```python
import pandas as pd

# 使用 pd.read_csv() 函数读取csv文件
data = pd.read_csv('.\data\data.csv')
print(data)
```

### 填充缺失数据

通常使用插入或删除的方法处理缺失的数据，不过为了保证数据集的连续性质，通常使用插入方式。

```python
"""
	填充缺失数据函数
	第一个参数 value：用于填充缺失值的标量值或字典。如果值是字典，则字典的键是列名，值是用于填充该列缺失值的标量值。
	第二个参数 method：指定填充缺失值的方式。'backfill'或'bfill'表示使用后续有效值进行填充（前向填充），'pad'或'ffill'表示使用前一个有效值进行填充（后向填充）。
	第三个参数 axis：{0, 1, None}，默认为0。指定填充缺失值的轴。0表示按列（垂直方向）填充，1表示按行（水平方向）填充，None表示同时按列和行填充。
"""
pd.fillna()
```

```python
input = data.iloc[:, 0:2]			# iloc 进行数据集索引
input = input.fillna(input.mean())	# 以平均值填充
print(input)
```

**`pd.fillna()`函数通常用于连续数据类型的缺失处理**。

```python
"""
	one-hot 编码函数
	第一个参数 data：需要进行 one-hot 编码的数据。可以是 Pandas DataFrame 或者一个 Series。
	第二个参数 prefix：创建 dummy 变量的前缀。如果没有指定，那么默认会使用列名作为前缀。
	第三个参数 prefix_sep：前缀与列名之间的分隔符。默认为 '_'。
	第四个参数 dummy_na：是否对 NA（缺失）值进行编码。如果为 True，那么会创建一个指示是否存在 NA 值的 dummy 变量。默认为 False。
	第五个参数 columns：需要进行 one-hot 编码的列名列表。如果为 None，那么会对所有分类变量进行编码。
	第六个参数 sparse：是否使用稀疏矩阵来存储结果。如果为 True，那么结果会是一个稀疏矩阵（Scipy.Sparse CSR matrix）。默认为 False。
	第七个参数 drop_first：是否删除第一类别以创建一个没有截距项的模型矩阵。如果为 True，那么结果中不包含第一类别的 dummy 变量。默认为 False。
	第八个参数 dtype：创建的 dummy 变量的数据类型。如果没有指定，那么默认会使用 float64 类型。
"""
pd.get_dummies()
```

```python
input = pd.get_dummies(input, dummy_na=True)
print(input)
```

**`pd.get_dummies()`函数通常用于分类数据类型的处理**。

### 转换为张量

```python
"""
	转换为numpy数组函数
"""
array.to_numpy()
```

```python
input_tensor = torch.Tensor(input.to_numpy(dtype=float))
```

## 3. 线性代数

### 标量

标量由只有一个元素的张量表示。

```python
import torch

x = torch.tensor(3.0)
y = torch.tensor(2.0)

x + y, x * y, x / y, x**y
```

### 向量

向量可以被视为标量值组成的列表。 这些标量值被称为向量的元素（element）或分量（component）。通过一维张量表示向量。

```python
x = torch.arange(4)
```

**列向量是向量的默认方向。**

### 矩阵和张量

矩阵是具有两个轴的张量。

对于两个矩阵而言，有以下运算：

1. 哈达玛积（按元素乘积）

$$
A \odot B = \left[ \begin{matrix} a_{11}b_{11}& a_{12}b_{12} & \dots  & a_{1n}b_{1n} \\ a_{11}b_{11}& a_{12}b_{12}& \dots &a_{1n}b_{1n} \\ \vdots & \vdots & \ddots &\vdots \\ a_{m1}b_{m1}& a_{m2}b_{m2}& \dots &a_{mn}b_{mn}
\end{matrix}\right]
$$

```python
A * B
```

2. 点积

$$
\bold{x^T y} =\sum x_iy_i 
$$

```python
torch.dot()
```

3. 矩阵-向量积

$$
\bold{Ax} = 
\left[
\begin{matrix}
\bold{a_1^T} \\
\bold{a_2^T} \\
\vdots \\
\bold{a_m^T}
\end{matrix}
\right]\bold{x} = 
\left[
\begin{matrix}
\bold{a_1^T x} \\
\bold{a_2^T x} \\
\vdots \\
\bold{a_m^T x}
\end{matrix}
\right]
$$

```python
torch.mv()
```

4. 矩阵乘法

```python
torch.matmul()
```

### 范数

范数是一种距离的表示。

$L_2$范数：
$$
||x||_2 = \sqrt{\sum_{i=1}^n x_i^2}
$$

```python
torch.norm()
```

$L_1$范数：
$$
||x||_1 = \sum_{i=1}^n|x_i|
$$

## 4. 微积分

### 多元函数的导数

梯度：
$$
\nabla f(\bold{x}) = \left[ \begin{matrix}\frac{\partial f(\bold{x})}{\partial x_1} & \frac{\partial f(\bold{x})}{\partial x_2} & \frac{\partial f(\bold{x})}{\partial x_3} & \cdots & \frac{\partial f(\bold{x})}{\partial x_n}\end{matrix}\right]
$$

### 自动微分

在深度学习框架中，系统会根据模型设计一个计算图，跟踪哪些数据通过哪些操作组合起来产生输出。自动微分使得系统能够在进行计算后随后反向传播梯度。

反向传播：跟踪整个计算图，填充关于每个参数的偏导数。

1. 对标量的自动微分

```python
x = torch.arange(4.0, requires_grad=True)

y = 2*torch.dot(x, x)

# 反向传播算法计算y对x的梯度
y.backward()
# x 具有grad(梯度)成员，使用zero_方法对其进行清零操作
x.grad.zero_()
```

2. 对向量的自动微分

```python
# 计算批量中每个样本的偏导数之和
x.grad.zero_()
y = x*x
y.sum().backward()
```

3. 求存在中间变量时的自动微分

```python
y = x*x
u = y.detach()
z = x*u
z.sum().backward()
```

